{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88f3d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "984f91ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdpsolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d700038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gridworld import GridWorld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26438ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDP():\n",
    "    def __init__(self, TPM, R_S, gamma=0.9):\n",
    "        \n",
    "        assert isinstance(TPM, torch.Tensor), \"TPM must be a torch.Tensor\"\n",
    "        assert TPM.ndim == 3, \"TPM must be a 3D tensor\"\n",
    "        assert TPM.shape[0] == TPM.shape[2], \"TPM must be square\"\n",
    "        assert isinstance(R_S, torch.Tensor), \"R_S must be a torch.Tensor\"\n",
    "        assert R_S.ndim == 1, \"R_S must be a 1D tensor\"\n",
    "        assert R_S.shape[0] == TPM.shape[0], \"Number of states in R_S must match number of states in TPM\"\n",
    "        assert isinstance(gamma, float), \"gamma must be a float\"\n",
    "\n",
    "        self.TPM = TPM\n",
    "        self.n_states = TPM.shape[0]\n",
    "        self.n_actions = TPM.shape[1]\n",
    "        self.R_S = R_S\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.value = None\n",
    "        self.policy_list = None\n",
    "        self.policy_matrix = None\n",
    "\n",
    "        self.T = None # marginalised transition matrix\n",
    "        self.M = None # successor representation\n",
    "\n",
    "    def get_rewards_stateaction(self) -> list:\n",
    "        \"\"\"\n",
    "        Get a list of of rewards for each action in each state, in preparation for 'MDPSolver'\n",
    "        as we do not distinguish between actions in the reward function, we give the same reward for each action in each state\n",
    "        \"\"\"\n",
    "        rewards = []\n",
    "        for i in range(self.n_states):\n",
    "            state_reward = []\n",
    "            for j in range(self.n_actions):\n",
    "                state_reward.append(self.R_S[i].item())\n",
    "            rewards.append(state_reward)\n",
    "\n",
    "        return rewards\n",
    "    \n",
    "    def get_TPM_sparse(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Get a sparse TPM in the format of \"MDPSolver\" \n",
    "        \"\"\"\n",
    "        tpm = self.TPM\n",
    "        sparse = []\n",
    "        for i in range(self.n_states):\n",
    "            for j in range(4):\n",
    "                for k in range(self.n_states):\n",
    "                    if tpm[i, j, k] > 0:\n",
    "                        sparse.append((i, j, k, float(tpm[i, j, k].item())))\n",
    "\n",
    "        return sparse \n",
    "\n",
    "    def get_matrix_from_mdpsolver_policy(self, policy_list) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Convert the policy from mdpsolver (which is a 1D array of the best action for each state)\n",
    "        to a 2D matrix representation of size [n_states, n_actions]\n",
    "        \"\"\"\n",
    "        policy = np.array(policy_list)\n",
    "        policy_matrix = torch.zeros(policy.shape[0], 4)\n",
    "        for i in range(policy.shape[0]):\n",
    "            policy_matrix[i, int(policy[i])] = 1.0\n",
    "\n",
    "        return policy_matrix\n",
    "\n",
    "    def solve(self):\n",
    "        \"\"\"\n",
    "        Solve the MDP using the mdpsolver library\n",
    "        \"\"\"\n",
    "        # Create a new MDP model instance\n",
    "        mdl = mdpsolver.model()\n",
    "        mdl.mdp(\n",
    "            discount            = self.gamma,\n",
    "            rewards             = self.get_rewards_stateaction(),\n",
    "            tranMatElementwise  = self.get_TPM_sparse(),\n",
    "        )\n",
    "        # Solve the MDP\n",
    "        mdl.solve()\n",
    "\n",
    "        self.policy_list = mdl.getPolicy()\n",
    "        self.policy_matrix = self.get_matrix_from_mdpsolver_policy(self.policy_list)\n",
    "        self.value = mdl.getValueVector()\n",
    "\n",
    "    def get_marginal_T(self):\n",
    "        \"\"\"\n",
    "        Calculate the marginalised transition matrix T(s'|s) given the \n",
    "        optimal policy and the environmental transition probability matrix.\n",
    "        \"\"\"\n",
    "        if self.policy_matrix is None:\n",
    "            self.solve()\n",
    "        \n",
    "        T = torch.zeros((self.n_states, self.n_states), dtype=torch.float32)\n",
    "        # M_{s,s'} = \\sum_{a} \\pi(a|s) T(s'|s,a)\n",
    "        for s in range(self.n_states):\n",
    "            for s_ in range(self.n_states):\n",
    "                T[s, s_] = torch.sum(self.policy_matrix[s] * self.TPM[s, :, s_])\n",
    "\n",
    "        self.T = T\n",
    "    \n",
    "    def get_SR_M(self):\n",
    "        \"\"\"\n",
    "        Calculate the successor representation M(s,s') under the optimal policy\n",
    "        \"\"\"\n",
    "        if self.T is None:\n",
    "            self.get_marginal_T()\n",
    "        \n",
    "        # M(s,s') = (I - \\gamma T)^{-1}\n",
    "        M = torch.linalg.inv(torch.eye(self.n_states) - self.gamma * self.T)\n",
    "\n",
    "        self.M = M\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7bd2adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x―x―x―x\n",
      "|     |\n",
      "x x x x\n",
      "|     |\n",
      "x x x x\n",
      "|     |\n",
      "x―x―x―x\n",
      "\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "GAMMA = 0.95\n",
    "\n",
    "gridworld = GridWorld(\n",
    "    3, 3, \n",
    "    #wall_horiz=[[0, 1],[1, 2]], \n",
    "    #wall_vert=[[1, 1]], \n",
    "    controllability=[0.5, 0.5], \n",
    "    wind=[0.0, 0.0])\n",
    "\n",
    "print(gridworld.grid)\n",
    "\n",
    "grid_str = f'{gridworld.grid}'\n",
    "\n",
    "TPM = gridworld.get_TPM()\n",
    "rewards = torch.zeros(gridworld.n_states)\n",
    "rewards[-3] = 1.0\n",
    "\n",
    "print(rewards)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4c9abf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successor representation M(s,s'):\n",
      "[[ 1.    0.    0.    0.95  0.    0.   18.05  0.    0.  ]\n",
      " [ 0.95  1.    0.    0.9   0.    0.   17.15  0.    0.  ]\n",
      " [ 0.9   0.95  1.    0.86  0.    0.   16.29  0.    0.  ]\n",
      " [ 0.    0.    0.    1.    0.    0.   19.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.95  1.    0.   18.05  0.    0.  ]\n",
      " [ 0.    0.    0.    0.9   0.95  1.   17.15  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.   20.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.   19.    1.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.   18.05  0.95  1.  ]]\n"
     ]
    }
   ],
   "source": [
    "mdp = MDP(TPM, rewards, gamma=GAMMA)\n",
    "mdp.get_SR_M()\n",
    "M = mdp.M\n",
    "print(\"Successor representation M(s,s'):\")\n",
    "print(np.round(M.numpy(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0fd88ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controllability matrix C(s,s'):\n",
      "[[20.   18.1  16.37 18.1   8.6  14.81 16.37 14.81 13.4 ]\n",
      " [18.1  20.   18.1  16.37  9.5  16.37 14.81 16.37 14.81]\n",
      " [16.37 18.1  20.   14.81  8.6  18.1  13.4  14.81 16.37]\n",
      " [18.1  16.37 14.81 20.    9.5  16.37 18.1  16.37 14.81]\n",
      " [16.37 18.1  16.37 18.1  10.5  18.1  16.37 18.1  16.37]\n",
      " [14.81 16.37 18.1  16.37  9.5  20.   14.81 16.37 18.1 ]\n",
      " [16.37 14.81 13.4  18.1   8.6  14.81 20.   18.1  16.37]\n",
      " [14.81 16.37 14.81 16.37  9.5  16.37 18.1  20.   18.1 ]\n",
      " [13.4  14.81 16.37 14.81  8.6  18.1  16.37 18.1  20.  ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controllability of states:\n",
      "tensor([140.5567, 144.4314, 140.5567, 144.4314, 148.3685, 144.4314, 140.5567,\n",
      "        144.4314, 140.5567])\n",
      "Controllability of overall system:\n",
      "tensor(1288.3210)\n"
     ]
    }
   ],
   "source": [
    "C = torch.zeros((gridworld.n_states, gridworld.n_states), dtype=torch.float32)\n",
    "for i in range(gridworld.n_states):\n",
    "    rewards = torch.zeros(gridworld.n_states)\n",
    "    rewards[i] = 1.0\n",
    "    mdp = MDP(TPM, rewards, gamma=GAMMA)\n",
    "    mdp.get_SR_M()\n",
    "    M = mdp.M\n",
    "    # print(f\"Successor representation M(s,s') for reward in state {i}:\")\n",
    "    # print(np.round(M.numpy(), 2))\n",
    "    C[:, i] = M[:, i]\n",
    "print(\"Controllability matrix C(s,s'):\")\n",
    "print(np.round(C.numpy(), 2))\n",
    "plt.imshow(C.numpy(), cmap='hot', interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "print(\"Controllability of states:\")\n",
    "c_bar = torch.sum(C, dim=1)\n",
    "print(c_bar)\n",
    "\n",
    "print(\"Controllability of overall system:\")\n",
    "c_bar_bar = torch.sum(C)\n",
    "print(c_bar_bar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generic312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
